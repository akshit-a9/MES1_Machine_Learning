{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Worksheet\n",
    "## Transforming Raw Data into Powerful Features\n",
    "\n",
    "Feature engineering is often considered the key to successful machine learning. In this workshop, you'll learn:\n",
    "\n",
    "1. **Feature Scaling & Normalization**\n",
    "2. **Polynomial & Interaction Features** \n",
    "3. **Categorical Encoding Techniques**\n",
    "4. **Feature Selection Methods**\n",
    "5. **Creating Features from DateTime & Text**\n",
    "6. **Real-world Examples & Best Practices**\n",
    "\n",
    "**\"Raw data is like a diamond in the rough - feature engineering is the art of cutting and polishing it.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression, load_boston, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler, \n",
    "    PolynomialFeatures, LabelEncoder, OneHotEncoder\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, f_regression, mutual_info_regression,\n",
    "    RFE, SelectFromModel\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Scaling and Normalization\n",
    "\n",
    "Different algorithms are sensitive to feature scales. Let's explore various scaling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data with different scales\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data = {\n",
    "    'age': np.random.normal(35, 10, n_samples),  # 20-50 range\n",
    "    'salary': np.random.normal(50000, 15000, n_samples),  # 20k-80k range\n",
    "    'experience': np.random.normal(8, 4, n_samples),  # 0-16 range\n",
    "    'rating': np.random.uniform(1, 5, n_samples)  # 1-5 range\n",
    "}\n",
    "\n",
    "# Add some correlation\n",
    "data['salary'] += data['experience'] * 2000\n",
    "data['rating'] += data['experience'] * 0.1\n",
    "\n",
    "df_original = pd.DataFrame(data)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Original Data Statistics:\")\n",
    "print(df_original.describe())\n",
    "\n",
    "# Visualize the original distributions\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "for i, col in enumerate(df_original.columns):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.hist(df_original[col], bins=30, alpha=0.7, color=f'C{i}')\n",
    "    plt.title(f'{col}\\n(μ={df_original[col].mean():.1f}, σ={df_original[col].std():.1f})')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Scaling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different scaling techniques\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),  # (X - mean) / std\n",
    "    'MinMaxScaler': MinMaxScaler(),      # (X - min) / (max - min)\n",
    "    'RobustScaler': RobustScaler()       # (X - median) / IQR\n",
    "}\n",
    "\n",
    "scaled_data = {}\n",
    "for name, scaler in scalers.items():\n",
    "    scaled_data[name] = pd.DataFrame(\n",
    "        scaler.fit_transform(df_original), \n",
    "        columns=df_original.columns\n",
    "    )\n",
    "\n",
    "# Visualize scaling effects\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "\n",
    "datasets = {'Original': df_original, **scaled_data}\n",
    "\n",
    "for row, (dataset_name, df) in enumerate(datasets.items()):\n",
    "    for col, column in enumerate(df.columns):\n",
    "        ax = axes[row, col]\n",
    "        ax.hist(df[column], bins=30, alpha=0.7, color=f'C{col}')\n",
    "        ax.set_title(f'{dataset_name}: {column}')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare statistics\n",
    "print(\"\\nScaling Comparison (means and stds):\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Means: {df.mean().round(3).values}\")\n",
    "    print(f\"Stds:  {df.std().round(3).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Scaling on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple regression problem\n",
    "X, y = make_regression(n_samples=1000, n_features=4, noise=0.1, random_state=42)\n",
    "\n",
    "# Make features have different scales\n",
    "X[:, 0] *= 100      # Large scale\n",
    "X[:, 1] *= 0.01     # Small scale\n",
    "X[:, 2] *= 10       # Medium scale\n",
    "# X[:, 3] stays as is\n",
    "\n",
    "feature_names = ['Large_Scale', 'Small_Scale', 'Medium_Scale', 'Normal_Scale']\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "print(\"Feature Scales:\")\n",
    "print(X_df.describe())\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Test different models with and without scaling\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'SVR': SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Without scaling\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2_no_scaling = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # With standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "    r2_with_scaling = r2_score(y_test, y_pred_scaled)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'R² (No Scaling)': r2_no_scaling,\n",
    "        'R² (With Scaling)': r2_with_scaling,\n",
    "        'Improvement': r2_with_scaling - r2_no_scaling\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nScaling Impact on Model Performance:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polynomial and Interaction Features\n",
    "\n",
    "Creating non-linear features from linear ones can dramatically improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a non-linear relationship\n",
    "np.random.seed(42)\n",
    "X_simple = np.random.uniform(-2, 2, (300, 2))\n",
    "y_nonlinear = (\n",
    "    X_simple[:, 0]**2 + \n",
    "    X_simple[:, 1]**2 + \n",
    "    X_simple[:, 0] * X_simple[:, 1] + \n",
    "    np.random.normal(0, 0.1, 300)\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df_poly = pd.DataFrame(X_simple, columns=['x1', 'x2'])\n",
    "df_poly['y'] = y_nonlinear\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y_nonlinear, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Visualize the relationship\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 3D plot\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(df_poly['x1'], df_poly['x2'], df_poly['y'], c=df_poly['y'], cmap='viridis')\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.set_zlabel('y')\n",
    "ax1.set_title('Original Non-linear Relationship')\n",
    "\n",
    "# 2D projections\n",
    "plt.subplot(132)\n",
    "plt.scatter(df_poly['x1'], df_poly['y'], alpha=0.6, c='blue')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('y')\n",
    "plt.title('y vs x1')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(df_poly['x2'], df_poly['y'], alpha=0.6, c='red')\n",
    "plt.xlabel('x2')\n",
    "plt.ylabel('y')\n",
    "plt.title('y vs x2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Linear vs Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare linear vs polynomial regression\n",
    "degrees = [1, 2, 3, 4]\n",
    "poly_results = []\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train_poly)\n",
    "    y_pred_test = model.predict(X_test_poly)\n",
    "    \n",
    "    # Calculate scores\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    poly_results.append({\n",
    "        'Degree': degree,\n",
    "        'Features': X_train_poly.shape[1],\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'Overfitting': train_r2 - test_r2\n",
    "    })\n",
    "    \n",
    "    # Create visualization mesh for degree 2\n",
    "    if degree == 2:\n",
    "        # Create mesh for prediction surface\n",
    "        x1_range = np.linspace(X_simple[:, 0].min(), X_simple[:, 0].max(), 50)\n",
    "        x2_range = np.linspace(X_simple[:, 1].min(), X_simple[:, 1].max(), 50)\n",
    "        X1_mesh, X2_mesh = np.meshgrid(x1_range, x2_range)\n",
    "        X_mesh = np.c_[X1_mesh.ravel(), X2_mesh.ravel()]\n",
    "        X_mesh_poly = poly.transform(X_mesh)\n",
    "        y_mesh_pred = model.predict(X_mesh_poly).reshape(X1_mesh.shape)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(f'Degree {degree}\\nTest R² = {test_r2:.3f}')\n",
    "    \n",
    "    # Show feature names for degree 2\n",
    "    if degree == 2:\n",
    "        feature_names = poly.get_feature_names_out(['x1', 'x2'])\n",
    "        plt.subplot(2, 4, i+5)\n",
    "        coef_importance = np.abs(model.coef_)\n",
    "        plt.bar(range(len(coef_importance)), coef_importance)\n",
    "        plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "        plt.ylabel('Coefficient Magnitude')\n",
    "        plt.title('Feature Importance (Degree 2)')\n",
    "        \n",
    "        print(f\"\\nDegree {degree} Features: {feature_names}\")\n",
    "        print(f\"Coefficients: {model.coef_.round(3)}\")\n",
    "\n",
    "# Plot prediction surface for degree 2\n",
    "if 'y_mesh_pred' in locals():\n",
    "    plt.subplot(2, 4, 7)\n",
    "    contour = plt.contourf(X1_mesh, X2_mesh, y_mesh_pred, levels=20, alpha=0.8, cmap='viridis')\n",
    "    plt.scatter(X_simple[:, 0], X_simple[:, 1], c=y_nonlinear, cmap='viridis', edgecolors='black')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Degree 2 Prediction Surface')\n",
    "\n",
    "# Performance comparison\n",
    "plt.subplot(2, 4, 8)\n",
    "degrees_list = [r['Degree'] for r in poly_results]\n",
    "train_r2s = [r['Train R²'] for r in poly_results]\n",
    "test_r2s = [r['Test R²'] for r in poly_results]\n",
    "\n",
    "plt.plot(degrees_list, train_r2s, 'o-', label='Train R²', linewidth=2)\n",
    "plt.plot(degrees_list, test_r2s, 's-', label='Test R²', linewidth=2)\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Train vs Test Performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results table\n",
    "poly_df = pd.DataFrame(poly_results)\n",
    "print(\"\\nPolynomial Degree Comparison:\")\n",
    "print(poly_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorical Encoding Techniques\n",
    "\n",
    "Machine learning models work with numbers, so we need to convert categorical variables appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample categorical data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "categorical_data = {\n",
    "    'city': np.random.choice(['NYC', 'LA', 'Chicago', 'Houston', 'Phoenix'], n_samples),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples, \n",
    "                                p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'color': np.random.choice(['Red', 'Green', 'Blue'], n_samples),\n",
    "    'size': np.random.choice(['Small', 'Medium', 'Large'], n_samples, p=[0.3, 0.5, 0.2])\n",
    "}\n",
    "\n",
    "# Create target variable with some relationship to categories\n",
    "city_effect = {'NYC': 10, 'LA': 8, 'Chicago': 6, 'Houston': 5, 'Phoenix': 4}\n",
    "education_effect = {'High School': 0, 'Bachelor': 5, 'Master': 8, 'PhD': 12}\n",
    "size_effect = {'Small': -2, 'Medium': 0, 'Large': 3}\n",
    "\n",
    "y_categorical = (\n",
    "    [city_effect[city] for city in categorical_data['city']] +\n",
    "    [education_effect[edu] for edu in categorical_data['education']] +\n",
    "    [size_effect[size] for size in categorical_data['size']] +\n",
    "    np.random.normal(0, 2, n_samples)\n",
    ")\n",
    "\n",
    "df_categorical = pd.DataFrame(categorical_data)\n",
    "df_categorical['target'] = y_categorical\n",
    "\n",
    "print(\"Categorical Data Sample:\")\n",
    "print(df_categorical.head(10))\n",
    "\n",
    "# Visualize categorical distributions\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "categorical_cols = ['city', 'education', 'color', 'size']\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    df_categorical[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'{col.title()} Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Box plot showing relationship with target\n",
    "    plt.subplot(2, 4, i+5)\n",
    "    df_categorical.boxplot(column='target', by=col, ax=plt.gca())\n",
    "    plt.title(f'Target vs {col.title()}')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Encoding Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from category_encoders import TargetEncoder, BinaryEncoder\n",
    "\n",
    "# Prepare data\n",
    "X_cat = df_categorical[categorical_cols]\n",
    "y_cat = df_categorical['target']\n",
    "\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "    X_cat, y_cat, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Different encoding techniques\n",
    "encoders = {\n",
    "    'Label Encoding': LabelEncoder(),\n",
    "    'One-Hot Encoding': OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "    'Ordinal Encoding': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),\n",
    "    'Target Encoding': TargetEncoder(),\n",
    "}\n",
    "\n",
    "encoding_results = []\n",
    "\n",
    "print(\"Encoding Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for encoding_name, encoder in encoders.items():\n",
    "    print(f\"\\n{encoding_name}:\")\n",
    "    \n",
    "    if encoding_name == 'Label Encoding':\n",
    "        # Label encoding for each column separately\n",
    "        X_train_encoded = X_train_cat.copy()\n",
    "        X_test_encoded = X_test_cat.copy()\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X_train_encoded[col] = le.fit_transform(X_train_cat[col])\n",
    "            # Handle unknown categories in test set\n",
    "            X_test_encoded[col] = X_test_cat[col].map(\n",
    "                dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            ).fillna(-1).astype(int)\n",
    "            \n",
    "            print(f\"  {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "    \n",
    "    elif encoding_name == 'Target Encoding':\n",
    "        X_train_encoded = encoder.fit_transform(X_train_cat, y_train_cat)\n",
    "        X_test_encoded = encoder.transform(X_test_cat)\n",
    "        print(f\"  Features created: {X_train_encoded.shape[1]}\")\n",
    "    \n",
    "    else:\n",
    "        X_train_encoded = encoder.fit_transform(X_train_cat)\n",
    "        X_test_encoded = encoder.transform(X_test_cat)\n",
    "        \n",
    "        if encoding_name == 'One-Hot Encoding':\n",
    "            feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "            print(f\"  Features created: {len(feature_names)}\")\n",
    "            print(f\"  Sample features: {feature_names[:10]}...\")\n",
    "        else:\n",
    "            print(f\"  Features created: {X_train_encoded.shape[1]}\")\n",
    "    \n",
    "    # Train a simple model to compare performance\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_encoded, y_train_cat)\n",
    "    \n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    r2 = r2_score(y_test_cat, y_pred)\n",
    "    mse = mean_squared_error(y_test_cat, y_pred)\n",
    "    \n",
    "    encoding_results.append({\n",
    "        'Encoding': encoding_name,\n",
    "        'Features': X_train_encoded.shape[1],\n",
    "        'R²': r2,\n",
    "        'MSE': mse\n",
    "    })\n",
    "    \n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "\n",
    "# Results comparison\n",
    "encoding_df = pd.DataFrame(encoding_results)\n",
    "print(\"\\n\\nEncoding Performance Comparison:\")\n",
    "print(encoding_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Encoding Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different encoding effects for education column\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Original relationship\n",
    "plt.subplot(2, 3, 1)\n",
    "education_means = df_categorical.groupby('education')['target'].mean().sort_values()\n",
    "education_means.plot(kind='bar')\n",
    "plt.title('Original: Education vs Target')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Average Target')\n",
    "\n",
    "# Label Encoding\n",
    "le_education = LabelEncoder()\n",
    "education_labels = le_education.fit_transform(df_categorical['education'])\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(education_labels, df_categorical['target'], alpha=0.5)\n",
    "plt.xlabel('Label Encoded Education')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Label Encoding')\n",
    "education_mapping = dict(zip(le_education.classes_, le_education.transform(le_education.classes_)))\n",
    "plt.xticks(list(education_mapping.values()), list(education_mapping.keys()), rotation=45)\n",
    "\n",
    "# One-Hot Encoding visualization\n",
    "ohe_education = OneHotEncoder(sparse_output=False)\n",
    "education_onehot = ohe_education.fit_transform(df_categorical[['education']])\n",
    "education_features = ohe_education.get_feature_names_out(['education'])\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "correlations = []\n",
    "for i, feature in enumerate(education_features):\n",
    "    corr = np.corrcoef(education_onehot[:, i], df_categorical['target'])[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "plt.bar(range(len(education_features)), correlations)\n",
    "plt.xticks(range(len(education_features)), \n",
    "           [f.replace('education_', '') for f in education_features], rotation=45)\n",
    "plt.ylabel('Correlation with Target')\n",
    "plt.title('One-Hot: Feature Correlations')\n",
    "\n",
    "# Target Encoding\n",
    "target_encoder = TargetEncoder()\n",
    "education_target_encoded = target_encoder.fit_transform(\n",
    "    df_categorical[['education']], df_categorical['target']\n",
    ")\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(education_target_encoded['education'], df_categorical['target'], alpha=0.5)\n",
    "plt.xlabel('Target Encoded Education')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Target Encoding')\n",
    "\n",
    "# Feature count comparison\n",
    "plt.subplot(2, 3, 5)\n",
    "feature_counts = [1, 1, len(education_features), 1]  # Original, Label, One-Hot, Target\n",
    "encoding_names = ['Original', 'Label', 'One-Hot', 'Target']\n",
    "plt.bar(encoding_names, feature_counts)\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Feature Count by Encoding')\n",
    "\n",
    "# Performance comparison\n",
    "plt.subplot(2, 3, 6)\n",
    "r2_scores = [result['R²'] for result in encoding_results]\n",
    "encoding_labels = [result['Encoding'] for result in encoding_results]\n",
    "plt.bar(range(len(r2_scores)), r2_scores)\n",
    "plt.xticks(range(len(encoding_labels)), encoding_labels, rotation=45)\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Model Performance by Encoding')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection Techniques\n",
    "\n",
    "Not all features are useful. Let's learn how to select the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with many features, some relevant, some not\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_many, y_many = make_regression(\n",
    "    n_samples=1000, \n",
    "    n_features=50,\n",
    "    n_informative=10,  # Only 10 features are actually informative\n",
    "    n_redundant=5,     # 5 features are redundant\n",
    "    noise=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "feature_names = [f'feature_{i}' for i in range(X_many.shape[1])]\n",
    "X_many_df = pd.DataFrame(X_many, columns=feature_names)\n",
    "\n",
    "X_train_many, X_test_many, y_train_many, y_test_many = train_test_split(\n",
    "    X_many, y_many, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {X_many.shape}\")\n",
    "print(f\"Informative features: 10\")\n",
    "print(f\"Redundant features: 5\")\n",
    "print(f\"Noise features: {50 - 10 - 5} = 35\")\n",
    "\n",
    "# Baseline performance with all features\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train_many, y_train_many)\n",
    "baseline_pred = baseline_model.predict(X_test_many)\n",
    "baseline_r2 = r2_score(y_test_many, baseline_pred)\n",
    "\n",
    "print(f\"\\nBaseline R² (all 50 features): {baseline_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection methods\n",
    "selection_methods = {\n",
    "    'f_regression': SelectKBest(score_func=f_regression, k=15),\n",
    "    'mutual_info': SelectKBest(score_func=mutual_info_regression, k=15)\n",
    "}\n",
    "\n",
    "univariate_results = []\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i, (method_name, selector) in enumerate(selection_methods.items()):\n",
    "    # Fit selector\n",
    "    X_train_selected = selector.fit_transform(X_train_many, y_train_many)\n",
    "    X_test_selected = selector.transform(X_test_many)\n",
    "    \n",
    "    # Get scores and selected features\n",
    "    scores = selector.scores_\n",
    "    selected_features = selector.get_support(indices=True)\n",
    "    \n",
    "    # Train model on selected features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_selected, y_train_many)\n",
    "    y_pred_selected = model.predict(X_test_selected)\n",
    "    r2_selected = r2_score(y_test_many, y_pred_selected)\n",
    "    \n",
    "    univariate_results.append({\n",
    "        'Method': method_name,\n",
    "        'Features Selected': len(selected_features),\n",
    "        'R²': r2_selected,\n",
    "        'Selected Features': selected_features.tolist()\n",
    "    })\n",
    "    \n",
    "    # Plot feature scores\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.bar(range(len(scores)), scores)\n",
    "    plt.axhline(y=np.sort(scores)[-15], color='red', linestyle='--', \n",
    "                label=f'Top 15 threshold')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{method_name.replace(\"_\", \" \").title()} Scores')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot selected vs non-selected\n",
    "    plt.subplot(2, 3, i+3)\n",
    "    selected_mask = np.zeros(len(scores), dtype=bool)\n",
    "    selected_mask[selected_features] = True\n",
    "    \n",
    "    plt.scatter(range(len(scores)), scores, \n",
    "               c=['red' if selected else 'blue' for selected in selected_mask],\n",
    "               alpha=0.6)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{method_name}: Selected (Red) vs Not Selected (Blue)')\n",
    "    \n",
    "    print(f\"\\n{method_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  R² Score: {r2_selected:.4f}\")\n",
    "    print(f\"  Top 10 features: {sorted(selected_features)[:10]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-based feature selection\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_based_methods = {\n",
    "    'Lasso': SelectFromModel(Lasso(alpha=0.1)),\n",
    "    'Random Forest': SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    'RFE (Linear)': RFE(LinearRegression(), n_features_to_select=15)\n",
    "}\n",
    "\n",
    "model_based_results = []\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "for i, (method_name, selector) in enumerate(model_based_methods.items()):\n",
    "    # Fit selector\n",
    "    X_train_selected = selector.fit_transform(X_train_many, y_train_many)\n",
    "    X_test_selected = selector.transform(X_test_many)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = selector.get_support(indices=True)\n",
    "    \n",
    "    # Train model on selected features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_selected, y_train_many)\n",
    "    y_pred_selected = model.predict(X_test_selected)\n",
    "    r2_selected = r2_score(y_test_many, y_pred_selected)\n",
    "    \n",
    "    model_based_results.append({\n",
    "        'Method': method_name,\n",
    "        'Features Selected': len(selected_features),\n",
    "        'R²': r2_selected,\n",
    "        'Selected Features': selected_features.tolist()\n",
    "    })\n",
    "    \n",
    "    # Get feature importances\n",
    "    if method_name == 'Random Forest':\n",
    "        importances = selector.estimator_.feature_importances_\n",
    "    elif method_name == 'Lasso':\n",
    "        importances = np.abs(selector.estimator_.coef_)\n",
    "    elif method_name == 'RFE (Linear)':\n",
    "        importances = selector.ranking_  # Lower ranking = more important\n",
    "        importances = 1.0 / importances  # Invert for plotting\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    colors = ['red' if idx in selected_features else 'blue' \n",
    "              for idx in range(len(importances))]\n",
    "    plt.bar(range(len(importances)), importances, color=colors, alpha=0.7)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'{method_name}\\nR² = {r2_selected:.4f}, Features = {len(selected_features)}')\n",
    "    \n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  R² Score: {r2_selected:.4f}\")\n",
    "    print(f\"  Features selected: {len(selected_features)}\")\n",
    "    print(f\"  Top 10 features: {sorted(selected_features)[:10]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_selection_results = (\n",
    "    [{'Method': 'Baseline (All)', 'Features Selected': 50, 'R²': baseline_r2}] +\n",
    "    univariate_results + \n",
    "    model_based_results\n",
    ")\n",
    "\n",
    "selection_df = pd.DataFrame(all_selection_results)\n",
    "print(\"Feature Selection Results:\")\n",
    "print(selection_df[['Method', 'Features Selected', 'R²']].round(4))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Performance vs number of features\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(selection_df['Features Selected'], selection_df['R²'], \n",
    "           s=100, alpha=0.7, c=range(len(selection_df)), cmap='viridis')\n",
    "\n",
    "for i, row in selection_df.iterrows():\n",
    "    plt.annotate(row['Method'], \n",
    "                (row['Features Selected'], row['R²']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Number of Features Selected')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Feature Selection: Performance vs Complexity')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot of R² scores\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = ['red' if method == 'Baseline (All)' else 'blue' \n",
    "          for method in selection_df['Method']]\n",
    "bars = plt.bar(range(len(selection_df)), selection_df['R²'], color=colors, alpha=0.7)\n",
    "plt.xticks(range(len(selection_df)), selection_df['Method'], rotation=45, ha='right')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Model Performance by Selection Method')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, r2 in zip(bars, selection_df['R²']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{r2:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DateTime and Text Feature Engineering\n",
    "\n",
    "Real-world data often contains dates and text that need special handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datetime and text data\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate datetime data\n",
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "dates = [start_date + datetime.timedelta(days=int(x)) \n",
    "         for x in np.random.uniform(0, 1000, n_samples)]\n",
    "\n",
    "# Generate text data (product reviews)\n",
    "positive_words = ['good', 'excellent', 'amazing', 'perfect', 'love', 'great', 'wonderful']\n",
    "negative_words = ['bad', 'terrible', 'awful', 'horrible', 'hate', 'worst', 'disappointing']\n",
    "neutral_words = ['okay', 'average', 'normal', 'fine', 'decent', 'acceptable']\n",
    "\n",
    "def generate_review(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        words = np.random.choice(positive_words, np.random.randint(3, 8))\n",
    "    elif sentiment == 'negative':\n",
    "        words = np.random.choice(negative_words, np.random.randint(3, 8))\n",
    "    else:\n",
    "        words = np.random.choice(neutral_words, np.random.randint(3, 8))\n",
    "    return ' '.join(words)\n",
    "\n",
    "sentiments = np.random.choice(['positive', 'negative', 'neutral'], n_samples, p=[0.4, 0.3, 0.3])\n",
    "reviews = [generate_review(sent) for sent in sentiments]\n",
    "\n",
    "# Create target variable based on datetime and text features\n",
    "# Seasonal effect (higher in winter months)\n",
    "seasonal_effect = [10 if date.month in [12, 1, 2] else \n",
    "                   5 if date.month in [3, 4, 11] else 0 \n",
    "                   for date in dates]\n",
    "\n",
    "# Sentiment effect\n",
    "sentiment_effect = [10 if sent == 'positive' else \n",
    "                   -5 if sent == 'negative' else 0 \n",
    "                   for sent in sentiments]\n",
    "\n",
    "# Weekly effect (lower on weekends)\n",
    "weekly_effect = [-3 if date.weekday() >= 5 else 0 for date in dates]\n",
    "\n",
    "y_complex = np.array(seasonal_effect) + np.array(sentiment_effect) + np.array(weekly_effect) + np.random.normal(0, 2, n_samples)\n",
    "\n",
    "df_complex = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'review': reviews,\n",
    "    'sentiment': sentiments,\n",
    "    'target': y_complex\n",
    "})\n",
    "\n",
    "print(\"Complex Data Sample:\")\n",
    "print(df_complex.head())\n",
    "\n",
    "# Visualize patterns\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Monthly pattern\n",
    "plt.subplot(2, 3, 1)\n",
    "df_complex['month'] = [d.month for d in df_complex['date']]\n",
    "monthly_avg = df_complex.groupby('month')['target'].mean()\n",
    "monthly_avg.plot(kind='bar')\n",
    "plt.title('Average Target by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Target')\n",
    "\n",
    "# Day of week pattern\n",
    "plt.subplot(2, 3, 2)\n",
    "df_complex['weekday'] = [d.weekday() for d in df_complex['date']]\n",
    "weekday_avg = df_complex.groupby('weekday')['target'].mean()\n",
    "weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "plt.bar(range(7), weekday_avg.values)\n",
    "plt.xticks(range(7), weekday_names)\n",
    "plt.title('Average Target by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Target')\n",
    "\n",
    "# Sentiment effect\n",
    "plt.subplot(2, 3, 3)\n",
    "df_complex.boxplot(column='target', by='sentiment', ax=plt.gca())\n",
    "plt.title('Target by Sentiment')\n",
    "\n",
    "# Time series plot\n",
    "plt.subplot(2, 3, 4)\n",
    "df_sorted = df_complex.sort_values('date')\n",
    "plt.scatter(df_sorted['date'], df_sorted['target'], alpha=0.3, s=10)\n",
    "plt.title('Target over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target')\n",
    "\n",
    "# Review length distribution\n",
    "plt.subplot(2, 3, 5)\n",
    "review_lengths = [len(review.split()) for review in df_complex['review']]\n",
    "plt.hist(review_lengths, bins=20, alpha=0.7)\n",
    "plt.title('Review Length Distribution')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Sentiment distribution\n",
    "plt.subplot(2, 3, 6)\n",
    "df_complex['sentiment'].value_counts().plot(kind='bar')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateTime Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(dates):\n",
    "    \"\"\"Extract comprehensive datetime features\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Basic temporal features\n",
    "    features['year'] = [d.year for d in dates]\n",
    "    features['month'] = [d.month for d in dates]\n",
    "    features['day'] = [d.day for d in dates]\n",
    "    features['weekday'] = [d.weekday() for d in dates]  # Monday=0, Sunday=6\n",
    "    features['quarter'] = [(d.month-1)//3 + 1 for d in dates]\n",
    "    \n",
    "    # Cyclical features (important for capturing cyclical nature)\n",
    "    features['month_sin'] = np.sin(2 * np.pi * features['month'] / 12)\n",
    "    features['month_cos'] = np.cos(2 * np.pi * features['month'] / 12)\n",
    "    features['weekday_sin'] = np.sin(2 * np.pi * features['weekday'] / 7)\n",
    "    features['weekday_cos'] = np.cos(2 * np.pi * features['weekday'] / 7)\n",
    "    features['day_sin'] = np.sin(2 * np.pi * features['day'] / 31)\n",
    "    features['day_cos'] = np.cos(2 * np.pi * features['day'] / 31)\n",
    "    \n",
    "    # Boolean flags\n",
    "    features['is_weekend'] = (features['weekday'] >= 5).astype(int)\n",
    "    features['is_month_start'] = (features['day'] <= 5).astype(int)\n",
    "    features['is_month_end'] = (features['day'] >= 25).astype(int)\n",
    "    features['is_winter'] = features['month'].isin([12, 1, 2]).astype(int)\n",
    "    features['is_summer'] = features['month'].isin([6, 7, 8]).astype(int)\n",
    "    \n",
    "    # Relative temporal features\n",
    "    min_date = min(dates)\n",
    "    features['days_since_start'] = [(d - min_date).days for d in dates]\n",
    "    features['weeks_since_start'] = features['days_since_start'] // 7\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract datetime features\n",
    "datetime_features = extract_datetime_features(df_complex['date'])\n",
    "\n",
    "print(\"DateTime Features:\")\n",
    "print(datetime_features.head(10))\n",
    "print(f\"\\nNumber of datetime features created: {datetime_features.shape[1]}\")\n",
    "\n",
    "# Visualize some cyclical features\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(datetime_features['month_sin'], datetime_features['month_cos'], \n",
    "           c=datetime_features['month'], cmap='tab12', alpha=0.6)\n",
    "plt.colorbar(label='Month')\n",
    "plt.xlabel('Month Sin')\n",
    "plt.ylabel('Month Cos')\n",
    "plt.title('Cyclical Month Encoding')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(datetime_features['weekday_sin'], datetime_features['weekday_cos'], \n",
    "           c=datetime_features['weekday'], cmap='tab7', alpha=0.6)\n",
    "plt.colorbar(label='Weekday')\n",
    "plt.xlabel('Weekday Sin')\n",
    "plt.ylabel('Weekday Cos')\n",
    "plt.title('Cyclical Weekday Encoding')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "feature_corrs = datetime_features.corrwith(pd.Series(y_complex)).abs().sort_values(ascending=False)\n",
    "feature_corrs[:15].plot(kind='bar')\n",
    "plt.title('DateTime Feature Correlations with Target')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop correlated datetime features:\")\n",
    "print(feature_corrs[:10].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(texts):\n",
    "    \"\"\"Extract various text features\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Basic text statistics\n",
    "    features['text_length'] = [len(text) for text in texts]\n",
    "    features['word_count'] = [len(text.split()) for text in texts]\n",
    "    features['avg_word_length'] = [np.mean([len(word) for word in text.split()]) \n",
    "                                  if len(text.split()) > 0 else 0 for text in texts]\n",
    "    \n",
    "    # Sentiment-related features\n",
    "    positive_count = [sum(1 for word in text.lower().split() if word in positive_words) \n",
    "                     for text in texts]\n",
    "    negative_count = [sum(1 for word in text.lower().split() if word in negative_words) \n",
    "                     for text in texts]\n",
    "    \n",
    "    features['positive_word_count'] = positive_count\n",
    "    features['negative_word_count'] = negative_count\n",
    "    features['sentiment_score'] = np.array(positive_count) - np.array(negative_count)\n",
    "    \n",
    "    # Word diversity\n",
    "    features['unique_words'] = [len(set(text.lower().split())) for text in texts]\n",
    "    features['word_diversity'] = features['unique_words'] / features['word_count']\n",
    "    features['word_diversity'] = features['word_diversity'].fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract text features\n",
    "text_features = extract_text_features(df_complex['review'])\n",
    "\n",
    "print(\"Text Features:\")\n",
    "print(text_features.head(10))\n",
    "print(f\"\\nNumber of text features created: {text_features.shape[1]}\")\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=20, stop_words='english')\n",
    "tfidf_features = tfidf.fit_transform(df_complex['review']).toarray()\n",
    "tfidf_feature_names = [f'tfidf_{name}' for name in tfidf.get_feature_names_out()]\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_feature_names)\n",
    "\n",
    "print(f\"\\nTF-IDF features created: {tfidf_df.shape[1]}\")\n",
    "print(f\"Feature names: {tfidf_feature_names[:10]}...\")\n",
    "\n",
    "# Visualize text features\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Text feature correlations\n",
    "plt.subplot(2, 3, 1)\n",
    "text_corrs = text_features.corrwith(pd.Series(y_complex)).abs().sort_values(ascending=False)\n",
    "text_corrs.plot(kind='bar')\n",
    "plt.title('Text Feature Correlations with Target')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Word count vs target\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(text_features['word_count'], y_complex, alpha=0.5)\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Word Count vs Target')\n",
    "\n",
    "# Sentiment score vs target\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(text_features['sentiment_score'], y_complex, alpha=0.5)\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Sentiment Score vs Target')\n",
    "\n",
    "# Top TF-IDF features by correlation\n",
    "plt.subplot(2, 3, 4)\n",
    "tfidf_corrs = tfidf_df.corrwith(pd.Series(y_complex)).abs().sort_values(ascending=False)\n",
    "tfidf_corrs[:10].plot(kind='bar')\n",
    "plt.title('Top TF-IDF Feature Correlations')\n",
    "plt.xlabel('TF-IDF Features')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Text length distribution by sentiment\n",
    "plt.subplot(2, 3, 5)\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    mask = df_complex['sentiment'] == sentiment\n",
    "    plt.hist(text_features.loc[mask, 'word_count'], alpha=0.5, label=sentiment, bins=15)\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Word Count Distribution by Sentiment')\n",
    "plt.legend()\n",
    "\n",
    "# Feature importance heatmap\n",
    "plt.subplot(2, 3, 6)\n",
    "feature_matrix = pd.concat([\n",
    "    text_features[['sentiment_score', 'word_count', 'positive_word_count', 'negative_word_count']],\n",
    "    tfidf_df.iloc[:, :6]  # Top 6 TF-IDF features\n",
    "], axis=1)\n",
    "\n",
    "correlation_matrix = feature_matrix.corrwith(pd.Series(y_complex)).to_frame('correlation')\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            yticklabels=True, xticklabels=['Correlation'])\n",
    "plt.title('Feature-Target Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop correlated text features:\")\n",
    "print(text_corrs.round(4))\n",
    "print(\"\\nTop correlated TF-IDF features:\")\n",
    "print(tfidf_corrs[:5].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensive Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features and compare model performance\n",
    "\n",
    "# Prepare different feature sets\n",
    "feature_sets = {\n",
    "    'Original': df_complex[['sentiment']],  # Just categorical\n",
    "    'DateTime': datetime_features,\n",
    "    'Text': text_features,\n",
    "    'TF-IDF': tfidf_df,\n",
    "    'DateTime + Text': pd.concat([datetime_features, text_features], axis=1),\n",
    "    'All Features': pd.concat([datetime_features, text_features, tfidf_df], axis=1)\n",
    "}\n",
    "\n",
    "# Need to encode categorical variables for original\n",
    "sentiment_encoded = pd.get_dummies(df_complex['sentiment'], prefix='sentiment')\n",
    "feature_sets['Original'] = sentiment_encoded\n",
    "\n",
    "# Test each feature set\n",
    "pipeline_results = []\n",
    "\n",
    "for feature_name, X_features in feature_sets.items():\n",
    "    # Split data\n",
    "    X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(\n",
    "        X_features, y_complex, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fs)\n",
    "    X_test_scaled = scaler.transform(X_test_fs)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train_fs)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_r2 = r2_score(y_train_fs, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_fs, y_pred_test)\n",
    "    train_mse = mean_squared_error(y_train_fs, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test_fs, y_pred_test)\n",
    "    \n",
    "    pipeline_results.append({\n",
    "        'Feature Set': feature_name,\n",
    "        'Num Features': X_features.shape[1],\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'Train MSE': train_mse,\n",
    "        'Test MSE': test_mse,\n",
    "        'Overfitting': train_r2 - test_r2\n",
    "    })\n",
    "\n",
    "# Results comparison\n",
    "pipeline_df = pd.DataFrame(pipeline_results)\n",
    "print(\"Feature Engineering Pipeline Results:\")\n",
    "print(pipeline_df.round(4))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Performance comparison\n",
    "plt.subplot(2, 3, 1)\n",
    "x_pos = range(len(pipeline_df))\n",
    "plt.bar([p - 0.2 for p in x_pos], pipeline_df['Train R²'], width=0.4, \n",
    "        label='Train R²', alpha=0.7)\n",
    "plt.bar([p + 0.2 for p in x_pos], pipeline_df['Test R²'], width=0.4, \n",
    "        label='Test R²', alpha=0.7)\n",
    "plt.xticks(x_pos, pipeline_df['Feature Set'], rotation=45)\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Train vs Test Performance')\n",
    "plt.legend()\n",
    "\n",
    "# Number of features vs performance\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(pipeline_df['Num Features'], pipeline_df['Test R²'], \n",
    "           s=100, alpha=0.7, c=range(len(pipeline_df)), cmap='viridis')\n",
    "for i, row in pipeline_df.iterrows():\n",
    "    plt.annotate(row['Feature Set'], \n",
    "                (row['Num Features'], row['Test R²']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.8)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Test R²')\n",
    "plt.title('Features vs Performance')\n",
    "\n",
    "# Overfitting analysis\n",
    "plt.subplot(2, 3, 3)\n",
    "colors = ['red' if x > 0.1 else 'green' for x in pipeline_df['Overfitting']]\n",
    "plt.bar(range(len(pipeline_df)), pipeline_df['Overfitting'], color=colors, alpha=0.7)\n",
    "plt.xticks(range(len(pipeline_df)), pipeline_df['Feature Set'], rotation=45)\n",
    "plt.ylabel('Overfitting (Train R² - Test R²)')\n",
    "plt.title('Overfitting Analysis')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Feature importance for best model\n",
    "best_idx = pipeline_df['Test R²'].idxmax()\n",
    "best_feature_set = pipeline_df.iloc[best_idx]['Feature Set']\n",
    "print(f\"\\nBest performing feature set: {best_feature_set}\")\n",
    "\n",
    "# Train final model on best features\n",
    "X_best = feature_sets[best_feature_set]\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(\n",
    "    X_best, y_complex, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_best = StandardScaler()\n",
    "X_train_best_scaled = scaler_best.fit_transform(X_train_best)\n",
    "X_test_best_scaled = scaler_best.transform(X_test_best)\n",
    "\n",
    "model_best = LinearRegression()\n",
    "model_best.fit(X_train_best_scaled, y_train_best)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_best.columns,\n",
    "    'importance': np.abs(model_best.coef_)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance (|Coefficient|)')\n",
    "plt.title(f'Top Features - {best_feature_set}')\n",
    "\n",
    "# Prediction vs actual\n",
    "plt.subplot(2, 3, 5)\n",
    "y_pred_final = model_best.predict(X_test_best_scaled)\n",
    "plt.scatter(y_test_best, y_pred_final, alpha=0.6)\n",
    "plt.plot([y_test_best.min(), y_test_best.max()], \n",
    "         [y_test_best.min(), y_test_best.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'Final Model Performance\\nR² = {r2_score(y_test_best, y_pred_final):.4f}')\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 3, 6)\n",
    "residuals = y_test_best - y_pred_final\n",
    "plt.scatter(y_pred_final, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Feature Scaling**: Essential for distance-based algorithms (KNN, SVM)\n",
    "2. **Polynomial Features**: Can capture non-linear relationships but risk overfitting\n",
    "3. **Categorical Encoding**: Choice depends on cardinality and relationship with target\n",
    "4. **Feature Selection**: Reduces overfitting and improves interpretability\n",
    "5. **DateTime Features**: Extract cyclical patterns and temporal relationships\n",
    "6. **Text Features**: Combine statistical features with TF-IDF for better performance\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Always split data before feature engineering to prevent data leakage\n",
    "- Use cyclical encoding for temporal features\n",
    "- Consider domain knowledge when creating features\n",
    "- Monitor overfitting when adding complex features\n",
    "- Use feature selection to reduce dimensionality\n",
    "- Validate feature importance and interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Survival Rate of Passengers on the Titanic Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
